{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta 3/15/2022 Load CSV and Numpy File Types in TensorFlow 2.0\n",
    "# src course Introduction to TensorFlow\n",
    "# git clone https://github.com/GoogleCloudPlatform/training-data-analyst \n",
    "# file src: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/labs/load_diff_filedata.ipynb\n",
    "\n",
    "#infra: work laptop, env anya_tf2\n",
    "\n",
    "#In the notebook interface, navigate to \n",
    "#  training-data-analyst > courses > machine_learning > deepdive2 > introduction_to_tensorflow > labs, \n",
    "#  and open load_diff_filedata.ipynb\n",
    "#Look at the complete solution, navigate to \n",
    "#  training-data-analyst > courses > machine_learning > deepdive2 > introduction_to_tensorflow > solutions, \n",
    "#  and open load_diff_filedata.ipynb\n",
    "\n",
    "#history\n",
    "#3/15/2022 REVIEW\n",
    "#      Download data files, preview data\n",
    "#      1) Read CSV files into a tf dataset\n",
    "#      Data preprocessing:\n",
    "#        Continious data (aka numeric), w/ normalization\n",
    "#        Categorical data\n",
    "#        Combined preprocessing layer\n",
    "#      2) Load NumPy data into a tf dataset\n",
    "#\n",
    "#      myXtra Doc: functools.partial()\n",
    "\n",
    "# Reference:\n",
    "#$error\n",
    "#  Jupyter notebook: 'head' is not recognized as an internal or external command, operable program or batch file.\n",
    "#$fix: \n",
    "#  https://stackoverflow.com/questions/61748573/jupyter-notebook-head-is-not-recognized-as-an-internal-or-external-command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sUtoed20cRJJ"
   },
   "source": [
    "# How to Load CSV and Numpy File Types in TensorFlow 2.0\n",
    "\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Load a CSV file into a `tf.data.Dataset`. \n",
    "2. Load Numpy data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Introduction \n",
    "\n",
    "In this lab, you load CSV data from a file into a `tf.data.Dataset`.  This tutorial provides an example of loading data from NumPy arrays into a `tf.data.Dataset` you also load text data.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in this student lab notebook -- try to complete this notebook first and then review [the solution notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/solutions/load_diff_filedata.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgZ9gjmPfSnK"
   },
   "source": [
    "## Load necessary libraries \n",
    "We will start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baYFZMW_bJHh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.6.3\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ncf5t6tgL5ZI"
   },
   "outputs": [],
   "source": [
    "#$my get data files\n",
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "#$myNote: downloaded file into C:\\Users\\chq-anyac\\.keras\\datasets\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ONE94qulk6S"
   },
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wuqj601Qw0Ml"
   },
   "source": [
    "## Load data\n",
    "\n",
    "This section provides an example of how to load CSV data from a file into a `tf.data.Dataset`.  The data used in this tutorial are taken from the Titanic passenger list. The model will predict the likelihood a passenger survived based on characteristics like age, gender, ticket class, and whether the person was traveling alone.\n",
    "\n",
    "To start, let's look at the top of the CSV file to see how it is formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54Dv7mCrf9Yw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "#$my - works in Linux/Unix system, ie. G Colab\n",
    "# !head {train_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$error  \n",
    "Jupyter notebook: 'head' is not recognized as an internal or external command, operable program or batch file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
      "\n",
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
      "\n",
      "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
      "\n",
      "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
      "\n",
      "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#$fix: https://stackoverflow.com/questions/61748573/jupyter-notebook-head-is-not-recognized-as-an-internal-or-external-command\n",
    "\n",
    "#$my - to make it work in Windows\n",
    "my_train_file_path = 'data/train.csv'\n",
    "n_lines = 5\n",
    "\n",
    "#option 1\n",
    "#read # lines in a file\n",
    "with open(my_train_file_path) as f:\n",
    "    for _ in range(n_lines): # first n lines\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
      "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
      "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
      "1,female,35.0,1,0,53.1,First,C,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "#option 2\n",
    "%alias head powershell -command \"& {Get-Content %s -Head 5}\"\n",
    "%head {my_train_file_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jC9lRhV-q_R3"
   },
   "source": [
    "You can [load this using pandas](pandas_dataframe.ipynb), and pass the NumPy arrays to TensorFlow. If you need to scale up to a large set of files, or need a loader that integrates with [TensorFlow and tf.data](../../guide/data.ipynb) then use the `tf.data.experimental.make_csv_dataset` function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67mfwr4v-mN_"
   },
   "source": [
    "The only column you need to identify explicitly is the one with the value that the model is intended to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXROZm5f3V4E"
   },
   "outputs": [],
   "source": [
    "# TODO 1: Add string name for label column \n",
    "LABEL_COLUMN = 'survived' \n",
    "LABELS = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t4N-plO4tDXd"
   },
   "source": [
    "Now read the CSV data from the file and create a dataset. \n",
    "\n",
    "(For the full documentation, see `tf.data.experimental.make_csv_dataset`)  \n",
    "https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset\n",
    "\n",
    "Reads CSV files into a dataset, where each element of the dataset is a (features, labels) tuple that corresponds to a batch of CSV rows. The features dictionary maps feature column names to `Tensors` containing the corresponding feature data, and labels is a `Tensor` containing the batch's label data.  More detail in part `Xtra`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIbUscB9sqha"
   },
   "outputs": [],
   "source": [
    "def get_dataset(file_path, **kwargs):\n",
    "# TODO 2\n",
    "# TODO: Read the CSV data from the file and create a dataset \n",
    "    dataset = tf.data.experimental.make_csv_dataset( \n",
    "    file_path,\n",
    "          batch_size=5, # Artificially small to make examples easier to show.\n",
    "          label_name=LABEL_COLUMN,\n",
    "          na_value=\"?\",\n",
    "          num_epochs=1,\n",
    "          ignore_errors=False, #$my was True\n",
    "          **kwargs\n",
    "    ) \n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$my create datasets\n",
    "raw_train_data = get_dataset(train_file_path)# TODO: Your code goes here.\n",
    "raw_test_data = get_dataset(test_file_path)# TODO: Your code goes here.\n",
    "\n",
    "#$my ds type\n",
    "raw_train_data.__class__ #class tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "sex                 : [b'male' b'male' b'male' b'male' b'male']\n",
      "age                 : [20. 28. 20. 25. 31.]\n",
      "n_siblings_spouses  : [1 0 1 1 0]\n",
      "parch               : [0 0 1 0 0]\n",
      "fare                : [ 7.925  7.896 15.742 26.    10.5  ]\n",
      "class               : [b'Third' b'Third' b'Third' b'Second' b'Second']\n",
      "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
      "embark_town         : [b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Southampton']\n",
      "alone               : [b'n' b'y' b'n' b'n' b'y']\n",
      "Labels: [1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "#$my show_batch() equivalent\n",
    "for feat, targ in raw_train_data.take(1):\n",
    "    print ('Features:')\n",
    "    for key, value in feat.items():\n",
    "      print(\"{:20s}: {}\".format(key,value.numpy()))\n",
    "    print ('Labels: {}'.format(targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v4oMO9MIxgTG"
   },
   "outputs": [],
   "source": [
    "def show_batch(dataset):\n",
    "  for batch, label in dataset.take(1):\n",
    "    for key, value in batch.items():\n",
    "      print(\"{:20s}: {}\".format(key,value.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vHUQFKoQI6G7"
   },
   "source": [
    "Each item in the dataset is a batch, represented as a tuple of (*many examples*, *many labels*). The data from the examples is organized in column-based tensors (rather than row-based tensors), each with as many elements as the batch size (5 in this case).\n",
    "\n",
    "It might help to see this yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HjrkJROoxoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'female' b'female' b'male' b'male' b'female']\n",
      "age                 : [22. 30. 15. 19. 30.]\n",
      "n_siblings_spouses  : [0 3 1 0 0]\n",
      "parch               : [0 0 1 0 0]\n",
      "fare                : [10.517 21.     7.229  7.775 56.929]\n",
      "class               : [b'Third' b'Second' b'Third' b'Third' b'First']\n",
      "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'E']\n",
      "embark_town         : [b'Southampton' b'Southampton' b'Cherbourg' b'Southampton' b'Cherbourg']\n",
      "alone               : [b'y' b'n' b'n' b'y' b'y']\n"
     ]
    }
   ],
   "source": [
    "show_batch(raw_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOYKQKmMj3D6"
   },
   "source": [
    "As you can see, the columns in the CSV are named. The dataset constructor will pick these names up automatically. If the file you are working with does not contain the column names in the first line, pass them in a list of strings to  the `column_names` argument in the `make_csv_dataset` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Av8_9L3tUg1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'male' b'male' b'female' b'female']\n",
      "age                 : [36. 51. 32. 28. 60.]\n",
      "n_siblings_spouses  : [1 0 0 0 1]\n",
      "parch               : [2 0 0 0 0]\n",
      "fare                : [120.      7.054   8.05    7.879  75.25 ]\n",
      "class               : [b'First' b'Third' b'Third' b'Third' b'First']\n",
      "deck                : [b'B' b'unknown' b'E' b'unknown' b'D']\n",
      "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Queenstown' b'Cherbourg']\n",
      "alone               : [b'n' b'y' b'y' b'y' b'n']\n"
     ]
    }
   ],
   "source": [
    "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
    "\n",
    "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZfhoX7bR9u4"
   },
   "source": [
    "This example is going to use all the available columns. If you need to omit some columns from the dataset, create a list of just the columns you plan to use, and pass it into the (optional) `select_columns` argument of the constructor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S1TzSkUKwsNP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 : [28. 49. 29. 17. 42.]\n",
      "n_siblings_spouses  : [0 1 1 1 1]\n",
      "class               : [b'Second' b'First' b'Second' b'Third' b'Second']\n",
      "deck                : [b'unknown' b'C' b'unknown' b'unknown' b'unknown']\n",
      "alone               : [b'y' b'n' b'n' b'n' b'n']\n"
     ]
    }
   ],
   "source": [
    "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
    "\n",
    "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9cryz31lxs3e"
   },
   "source": [
    "## Data preprocessing\n",
    "\n",
    "A CSV file can contain a variety of data types. Typically you want to convert from those mixed types to a fixed length vector before feeding the data into your model.\n",
    "\n",
    "TensorFlow has a built-in system for describing common input conversions: `tf.feature_column`, see [this tutorial](https://www.tensorflow.org/tutorials/structured_data/feature_columns) for details.  \n",
    "https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "\n",
    "\n",
    "You can preprocess your data using any tool you like (like [nltk](https://www.nltk.org/) or [sklearn](https://scikit-learn.org/stable/)), and just pass the processed output to TensorFlow. \n",
    "\n",
    "\n",
    "The primary advantage of doing the preprocessing inside your model is that when you export the model it includes the preprocessing. This way you can pass the raw data directly to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9AsbaFmCeJtF"
   },
   "source": [
    "### Continuous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xl0Q0DcfA_rt"
   },
   "source": [
    "If your data is already in an appropriate numeric format, you can pack the data into a vector before passing it off to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Yfji3J5BMxz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                 : [50. 24. 29. 24. 28.]\n",
      "n_siblings_spouses  : [2. 0. 1. 0. 0.]\n",
      "parch               : [0. 0. 1. 0. 0.]\n",
      "fare                : [133.65   13.     10.462  69.3    52.   ]\n"
     ]
    }
   ],
   "source": [
    "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
    "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
    "temp_dataset = get_dataset(train_file_path, \n",
    "                           select_columns=SELECT_COLUMNS,\n",
    "                           column_defaults = DEFAULTS)\n",
    "\n",
    "show_batch(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zEUhI8kZCfq8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('age',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([50., 44., 58., 30., 28.], dtype=float32)>),\n",
       "              ('n_siblings_spouses',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 1., 0., 0., 0.], dtype=float32)>),\n",
       "              ('parch',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 0., 1., 0., 0.], dtype=float32)>),\n",
       "              ('fare',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 26.   ,  26.   , 153.462,   7.896,   7.896], dtype=float32)>)]),\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 0, 1, 0, 0])>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch, labels_batch = next(iter(temp_dataset)) \n",
    "\n",
    "#$my preview\n",
    "example_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IP45_2FbEKzn"
   },
   "source": [
    "Here's a simple function that will pack together all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JQ0hNSL8CC3a"
   },
   "outputs": [],
   "source": [
    "def pack(features, label):\n",
    "  return tf.stack(list(features.values()), axis=-1), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75LA9DisEIoE"
   },
   "source": [
    "Apply this to each element of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnP2Z2lwCTRl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30.     0.     0.     8.663]\n",
      " [24.     1.     0.    16.1  ]\n",
      " [26.     1.     1.    26.   ]\n",
      " [17.     0.     0.     8.663]\n",
      " [ 7.     0.     2.    26.25 ]]\n",
      "\n",
      "[0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "packed_dataset = temp_dataset.map(pack)\n",
    "\n",
    "for features, labels in packed_dataset.take(1):\n",
    "  print(features.numpy())\n",
    "  print()\n",
    "  print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1VBvmaFrFU6J"
   },
   "source": [
    "If you have mixed datatypes you may want to separate out these simple-numeric fields. The `tf.feature_column` api can handle them, but this incurs some overhead and should be avoided unless really necessary. Switch back to the mixed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad-IQ_JPFQge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'male' b'female' b'female' b'female' b'female']\n",
      "age                 : [40.5 40.  32.   2.  17. ]\n",
      "n_siblings_spouses  : [0 0 0 0 4]\n",
      "parch               : [0 0 0 1 2]\n",
      "fare                : [ 7.75  13.    13.    10.462  7.925]\n",
      "class               : [b'Third' b'Second' b'Second' b'Third' b'Third']\n",
      "deck                : [b'unknown' b'unknown' b'unknown' b'G' b'unknown']\n",
      "embark_town         : [b'Queenstown' b'Southampton' b'Southampton' b'Southampton' b'Southampton']\n",
      "alone               : [b'y' b'y' b'y' b'n' b'n']\n"
     ]
    }
   ],
   "source": [
    "show_batch(raw_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSrYNKKcIdav"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('age',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([31., 28., 18., 27., 46.], dtype=float32)>),\n",
       "              ('n_siblings_spouses',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 1.], dtype=float32)>),\n",
       "              ('parch',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 2., 0., 0.], dtype=float32)>),\n",
       "              ('fare',\n",
       "               <tf.Tensor: shape=(5,), dtype=float32, numpy=array([13.   ,  6.95 , 13.   ,  7.896, 61.175], dtype=float32)>)]),\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 0, 1, 0, 0])>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch, labels_batch = next(iter(temp_dataset)) \n",
    "\n",
    "#$my preview\n",
    "example_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5VtThKfGPaQ"
   },
   "source": [
    "So define a more general preprocessor that selects a list of numeric features and packs them into a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DRishYYGS-m"
   },
   "outputs": [],
   "source": [
    "class PackNumericFeatures(object):\n",
    "  def __init__(self, names):\n",
    "    self.names = names\n",
    "\n",
    "  def __call__(self, features, labels):\n",
    "    numeric_features = [features.pop(name) for name in self.names]\n",
    "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
    "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
    "    features['numeric'] = numeric_features\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SeZka9AHfqD"
   },
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']\n",
    "\n",
    "packed_train_data = raw_train_data.map(\n",
    "    PackNumericFeatures(NUMERIC_FEATURES))\n",
    "\n",
    "packed_test_data = raw_test_data.map(\n",
    "    PackNumericFeatures(NUMERIC_FEATURES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFrw0YobIbUB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex                 : [b'female' b'female' b'male' b'male' b'male']\n",
      "class               : [b'First' b'Third' b'First' b'Third' b'Third']\n",
      "deck                : [b'B' b'unknown' b'unknown' b'unknown' b'unknown']\n",
      "embark_town         : [b'Cherbourg' b'Queenstown' b'Southampton' b'Southampton' b'Southampton']\n",
      "alone               : [b'y' b'y' b'y' b'n' b'y']\n",
      "numeric             : [[44.     0.     0.    27.721]\n",
      " [28.     0.     0.     7.787]\n",
      " [45.     0.     0.    35.5  ]\n",
      " [28.     8.     2.    69.55 ]\n",
      " [16.     0.     0.     8.05 ]]\n"
     ]
    }
   ],
   "source": [
    "show_batch(packed_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_EPUS8fPLUb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OrderedDict([('sex',\n",
       "               <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'female', b'female', b'female', b'male', b'male'], dtype=object)>),\n",
       "              ('class',\n",
       "               <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'Third', b'Second', b'Third', b'First', b'First'], dtype=object)>),\n",
       "              ('deck',\n",
       "               <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'unknown', b'unknown', b'B'], dtype=object)>),\n",
       "              ('embark_town',\n",
       "               <tf.Tensor: shape=(5,), dtype=string, numpy=\n",
       "               array([b'Cherbourg', b'Southampton', b'Cherbourg', b'Southampton',\n",
       "                      b'Cherbourg'], dtype=object)>),\n",
       "              ('alone',\n",
       "               <tf.Tensor: shape=(5,), dtype=string, numpy=array([b'n', b'n', b'n', b'y', b'y'], dtype=object)>),\n",
       "              ('numeric',\n",
       "               <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "               array([[14.   ,  1.   ,  0.   , 11.242],\n",
       "                      [22.   ,  1.   ,  1.   , 29.   ],\n",
       "                      [ 0.75 ,  2.   ,  1.   , 19.258],\n",
       "                      [28.   ,  0.   ,  0.   , 47.1  ],\n",
       "                      [46.   ,  0.   ,  0.   , 79.2  ]], dtype=float32)>)]),\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([1, 1, 1, 0, 0])>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch, labels_batch = next(iter(packed_train_data)) \n",
    "\n",
    "#$my preview\n",
    "example_batch, labels_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2maE8d2ijsq"
   },
   "source": [
    "#### Data Normalization\n",
    "\n",
    "Continuous data should always be normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKT1ASWpwH46"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
    "desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>627.0</td>\n",
       "      <td>29.631308</td>\n",
       "      <td>12.511818</td>\n",
       "      <td>0.75</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>28.0000</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>80.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <td>627.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>8.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>627.0</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>627.0</td>\n",
       "      <td>34.385399</td>\n",
       "      <td>54.597730</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>15.0458</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count       mean        std   min      25%      50%  \\\n",
       "age                 627.0  29.631308  12.511818  0.75  23.0000  28.0000   \n",
       "n_siblings_spouses  627.0   0.545455   1.151090  0.00   0.0000   0.0000   \n",
       "parch               627.0   0.379585   0.792999  0.00   0.0000   0.0000   \n",
       "fare                627.0  34.385399  54.597730  0.00   7.8958  15.0458   \n",
       "\n",
       "                        75%       max  \n",
       "age                 35.0000   80.0000  \n",
       "n_siblings_spouses   1.0000    8.0000  \n",
       "parch                0.0000    5.0000  \n",
       "fare                31.3875  512.3292  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$my \n",
    "desc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cHHstcKPsMXM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29.631  0.545  0.38  34.385] [12.512  1.151  0.793 54.598]\n"
     ]
    }
   ],
   "source": [
    "# TODO 1\n",
    "MEAN = np.array(desc.T['mean'])# TODO: Your code goes here.\n",
    "STD = np.array(desc.T['std'])# TODO: Your code goes here.\n",
    "\n",
    "print(MEAN, STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REKqO_xHPNx0"
   },
   "outputs": [],
   "source": [
    "def normalize_numeric_data(data, mean, std):\n",
    "  # Center the data\n",
    "  # TODO 2\n",
    "    return (data-mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VPsoMUgRCpUM"
   },
   "source": [
    "Now create a numeric column.  \n",
    "https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column  \n",
    "The `tf.feature_columns.numeric_column` API accepts a `normalizer_fn` argument, which will be run on each batch.\n",
    "\n",
    "Bind the `MEAN` and `STD` to the normalizer fn using [`functools.partial`](https://docs.python.org/3/library/functools.html#functools.partial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bw0I35xRS57V"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x0000018233DFD9D8>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what you just created.\n",
    "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
    "\n",
    "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
    "numeric_columns = [numeric_column]\n",
    "numeric_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZxcHXc6LCa7"
   },
   "source": [
    "When you train the model, include this feature column to select and center this block of numeric data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b61NM76Ot_kb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[14.   ,  1.   ,  0.   , 11.242],\n",
       "       [22.   ,  1.   ,  1.   , 29.   ],\n",
       "       [ 0.75 ,  2.   ,  1.   , 19.258],\n",
       "       [28.   ,  0.   ,  0.   , 47.1  ],\n",
       "       [46.   ,  0.   ,  0.   , 79.2  ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch['numeric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-r_4EAJAZoI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.249,  0.395, -0.479, -0.424],\n",
       "       [-0.61 ,  0.395,  0.782, -0.099],\n",
       "       [-2.308,  1.264,  0.782, -0.277],\n",
       "       [-0.13 , -0.474, -0.479,  0.233],\n",
       "       [ 1.308, -0.474, -0.479,  0.821]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
    "numeric_layer(example_batch).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M37oD2VcCO4R"
   },
   "source": [
    "The mean based normalization used here requires knowing the means of each column ahead of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tSyrkSQwYHKi"
   },
   "source": [
    "### Categorical data\n",
    "\n",
    "Some of the columns in the CSV data are categorical columns. That is, the content should be one of a limited set of options.\n",
    "\n",
    "Use the `tf.feature_column` API to create a collection with a `tf.feature_column.indicator_column` for each categorical column.  \n",
    "https://www.tensorflow.org/api_docs/python/tf/feature_column/indicator_column  \n",
    "https://www.tensorflow.org/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWDniduKMw-C"
   },
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kkxLdrsLwHPT"
   },
   "outputs": [],
   "source": [
    "categorical_columns = [] #list\n",
    "for feature, vocab in CATEGORIES.items():\n",
    "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=feature, vocabulary_list=vocab)\n",
    "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H18CxpHY_Nma"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
       " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what you just created.\n",
    "categorical_columns # list of tensorflow.python.feature_column.feature_column_v2.IndicatorColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_indicator (1, 3)\n",
      "deck_indicator (1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'categorical_column': {'class_name': 'VocabularyListCategoricalColumn',\n",
       "  'config': {'key': 'class',\n",
       "   'vocabulary_list': ('First', 'Second', 'Third'),\n",
       "   'dtype': 'string',\n",
       "   'default_value': -1,\n",
       "   'num_oov_buckets': 0}}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$my preview\n",
    "print(categorical_columns[1].name, categorical_columns[1].variable_shape)\n",
    "print(categorical_columns[2].name, categorical_columns[2].variable_shape)\n",
    "categorical_columns[1].get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "10\n",
      "3\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$my preview - how many total features resulted\n",
    "[print(cat_cols.variable_shape[1]) for cat_cols in categorical_columns];\n",
    "\n",
    "cat_cols_total = 0\n",
    "for cat_cols in categorical_columns:\n",
    "    cat_cols_total = cat_cols_total + cat_cols.variable_shape[1]\n",
    "    \n",
    "cat_cols_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7mACuOsArUH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
    "print(categorical_layer(example_batch).numpy()[0])\n",
    "#$my preview\n",
    "#print(categorical_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7-1QG99_1sN"
   },
   "source": [
    "This will be become part of a data processing input later when you build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPWkC4_1l3IG"
   },
   "source": [
    "### Combined preprocessing layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R3QAjo1qD4p9"
   },
   "source": [
    "Add the two feature column collections and pass them to a `tf.keras.layers.DenseFeatures` to create an input layer that will extract and preprocess both input types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-OYK7GnaH0r"
   },
   "outputs": [],
   "source": [
    "# TODO 1\n",
    "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns) # TODO: Your code goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m7_U_K0UMSVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.     1.     0.     0.     1.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     0.     0.     1.     0.     0.    -1.249  0.395\n",
      " -0.479 -0.424  0.     1.   ]\n"
     ]
    }
   ],
   "source": [
    "print(preprocessing_layer(example_batch).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex_indicator\n",
      "class_indicator\n",
      "deck_indicator\n",
      "embark_town_indicator\n",
      "alone_indicator\n",
      "numeric\n"
     ]
    }
   ],
   "source": [
    "#$my preview - order of all features, alphabetcial order explains 'numeric' before 'sex_indicator'\n",
    "preprocessing_layer.__class__ #keras.feature_column.dense_features_v2.DenseFeatures\n",
    "[print(k.name) for k in categorical_columns];\n",
    "[print(k.name) for k in numeric_columns];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlF_omQqtnOP"
   },
   "source": [
    "### Next Step\n",
    "\n",
    "A next step would be to build a build a `tf.keras.Sequential`, starting with the `preprocessing_layer`, which is beyond the scope of this lab.  We will cover the Keras Sequential API in the next Lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NumPy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary libraries \n",
    "First, restart the Kernel.  Then, we will start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.6.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version: \",tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from `.npz` file\n",
    "\n",
    "We use the MNIST dataset in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$myNote: downloaded file into C:\\Users\\chq-anyac\\.keras\\datasets\\mnist.npz (4 .npy files: ie. x_train.npy, x_test.npy)\n",
    "\n",
    "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
    "\n",
    "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
    "with np.load(path) as data:\n",
    "# TODO 1\n",
    "  train_examples = data['x_train']# TODO: Your code goes here.\n",
    "  train_labels = data['y_train'] #TODO: Your code goes here.\n",
    "  test_examples = data['x_test'] # TODO: Your code goes here.\n",
    "  test_labels = data['y_test'] # TODO: Your code goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NumPy arrays with `tf.data.Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming you have an array of examples and a corresponding array of labels, pass the two arrays as a tuple into `tf.data.Dataset.from_tensor_slices` to create a `tf.data.Dataset`.  \n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels)) # TODO: Your code goes here.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels)) # TODO: Your code goes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Labels: 5\n"
     ]
    }
   ],
   "source": [
    "for feat, targ in train_dataset.take(1):\n",
    "    print ('Features: {}'.format(feat)) #class 'tensorflow.python.framework.ops.EagerTensor'\n",
    "    print ('Labels: {}'.format(targ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step\n",
    "\n",
    "A next step would be to build a build a `tf.keras.Sequential`, starting with the `preprocessing_layer`, which is beyond the scope of this lab.  We will cover the Keras Sequential API in the next Lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources \n",
    "1. Load text data - this link: https://www.tensorflow.org/tutorials/load_data/text\n",
    "2. TF.text - this link:  https://www.tensorflow.org/tutorials/tensorflow_text/intro\n",
    "3. Load image daeta - https://www.tensorflow.org/tutorials/load_data/images\n",
    "4. Read data into a Pandas DataFrame - https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\n",
    "5. How to represent Unicode strings in TensorFlow - https://www.tensorflow.org/tutorials/load_data/unicode\n",
    "6. TFRecord and tf.Example -  https://www.tensorflow.org/tutorials/load_data/tfrecord                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2020 Google Inc.\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xtra\n",
    "\n",
    "### Preview a .csv file\n",
    "$error  \n",
    "Jupyter notebook: 'head' is not recognized as an internal or external command, operable program or batch file.\n",
    "\n",
    "https://stackoverflow.com/questions/61748573/jupyter-notebook-head-is-not-recognized-as-an-internal-or-external-command\n",
    "\n",
    "$my #option 3 - hardcode file path  \n",
    "or 'data\\\\train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
      "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
      "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
      "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
      "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
      "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
      "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
      "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
      "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
      "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head 'data/train.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc: tf.data.experimental.make_csv_dataset\n",
    "Reads CSV files into a dataset\n",
    "\n",
    "TensorFlow -> API -> TensorFlow Core v2.8.0 -> Python  \n",
    "https://www.tensorflow.org/api_docs/python/tf/data/experimental/make_csv_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$xtra doc\n",
    "doc_filename = 'data/doc_example.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature_A,Feature_B\r\n",
      "1,a\r\n",
      "2,b\r\n",
      "3,c\r\n",
      "4,d"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head 'data/doc_example.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the dataset is repeated indefinitely, reshuffling the order each time. This behavior can be modified by setting the `num_epochs` and `shuffle` arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Feature_A': array([4, 3]), 'Feature_B': array([b'd', b'c'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# No label column specified\n",
    "dataset = tf.data.experimental.make_csv_dataset(doc_filename, batch_size=2)\n",
    "#dataset = tf.data.experimental.make_csv_dataset(doc_filename, batch_size=2, shuffle=False)\n",
    "iterator = dataset.as_numpy_iterator()\n",
    "print(dict(next(iterator)))\n",
    "\n",
    "# prints a dictionary of batched features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('Feature_A', array([2, 3]))]), array([b'b', b'c'], dtype=object))\n"
     ]
    }
   ],
   "source": [
    "# Set Feature_B as label column\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    doc_filename, batch_size=2, label_name=\"Feature_B\")\n",
    "iterator = dataset.as_numpy_iterator()\n",
    "print(next(iterator))\n",
    "\n",
    "# prints (features, labels) tuple:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc: functools.partial()\n",
    "https://docs.python.org/3/library/functools.html#functools.partial\n",
    "\n",
    "The `partial()` is used for partial function application which “freezes” some portion of a function’s arguments and/or keywords resulting in a new object with a simplified signature. For example, `partial()` can be used to create a callable that behaves like the `int()` function where the base argument defaults to two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#$xtra doc\n",
    "#from functools import partial\n",
    "basetwo = functools.partial(int, base=2)\n",
    "basetwo.__doc__ = 'Convert base 2 string to an int.'\n",
    "basetwo('10010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 123\n",
      "18 18\n"
     ]
    }
   ],
   "source": [
    "#original function int()\n",
    "#refer to https://docs.python.org/3/library/functions.html#int\n",
    "\n",
    "#default base=10\n",
    "print(int(\"123\"), 1*(10**2) + 2*(10**1) + 3*(10**0))\n",
    "#change base=2\n",
    "print(int('10010', base=2), 1*(2**4) + 0*(2**3) + 0*(2**2) + 1*(2**1) + 0*(2**0))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "csv.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m90"
  },
  "kernelspec": {
   "display_name": "anya_tf2",
   "language": "python",
   "name": "anya_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
