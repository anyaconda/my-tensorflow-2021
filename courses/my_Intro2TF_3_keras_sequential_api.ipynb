{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta 3/29/2022 TensorFlow2 Introducing the Keras Sequential API (not on Vertex AI Platform)\n",
    "# src course Introduction to TensorFlow\n",
    "# git clone https://github.com/GoogleCloudPlatform/training-data-analyst \n",
    "# file src: https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/deepdive2/introduction_to_tensorflow/labs/3_keras_sequential_api.ipynb\n",
    "\n",
    "#infra: work laptop, env anya_tf2\n",
    "# pip install google-cloud-aiplatform\n",
    "# google-cloud-aiplatform                    1.11.0\n",
    "\n",
    "#In the notebook interface, navigate to \n",
    "#  training-data-analyst > courses > machine_learning > deepdive2 > introduction_to_tensorflow > labs, \n",
    "#  and open 3_keras_sequential_api.ipynb\n",
    "#Look at the complete solution, navigate to \n",
    "#  training-data-analyst > courses > machine_learning > deepdive2 > introduction_to_tensorflow > solutions, \n",
    "#  and open 3_keras_sequential_api.ipynb\n",
    "\n",
    "#history\n",
    "#3/23/2022 REVIEW $ac\n",
    "#      Build a DNN model using the Keras Sequential API\n",
    "#      Learn how to use feature columns in a Keras model\n",
    "#      Learn how to train a model with Keras\n",
    "#      High-level model evaluation\n",
    "#      Make predictions with the Keras model\n",
    "#\n",
    "#      here: build a simple deep neural network model using the Keras sequential api and feature columns; call our model for online prediciton.\n",
    "#      $note: Deploy and predict in GCP and Vertex AI wouldn't work outside of GCP, refer to solution file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing the Keras Sequential API on Vertex AI Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning objectives**\n",
    "  1. Build a DNN model using the Keras Sequential API\n",
    "  1. Learn how to use feature columns in a Keras model\n",
    "  1. Learn how to train a model with Keras\n",
    "  1. Learn how to save/load, and deploy a Keras model on GCP\n",
    "  1. Learn how to deploy the Model to Vertex AI and make predictions with the Keras model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Keras sequential API](https://keras.io/models/sequential/) allows you to create Tensorflow models layer-by-layer. This is useful for building most kinds of machine learning models but it does not allow you to create models that share layers, re-use layers or have multiple inputs or outputs. \n",
    "\n",
    "In this lab, we'll see how to build a simple deep neural network model using the Keras sequential api and feature columns. Once we have trained our model, we will deploy it using Vertex AI and see how to call our model for online prediciton.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__  in this student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/3_keras_sequential_api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing the necessary libraries for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.3\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from google.cloud import aiplatform\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Dense, DenseFeatures\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "print(tf.__version__)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the taxifare dataset, using the CSV files that we created in the first notebook of this sequence. Those files have been saved into `../data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$my - works in Linux/Unix system, ie. G Colab\n",
    "#!ls -l ../data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!head ../data/taxi*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 chq-anyac 1049089  61473 Mar 23 13:16 data/toy_data/taxi-test.csv\n",
      "-rw-r--r-- 1 chq-anyac 1049089 288831 Mar 23 13:16 data/toy_data/taxi-train.csv\n",
      "-rw-r--r-- 1 chq-anyac 1049089  61082 Mar 23 13:16 data/toy_data/taxi-valid.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls -l data/toy_data/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> data/toy_data/taxi-test.csv <==\n",
      "6.0,2013-03-27 03:35:00 UTC,-73.977672,40.784052,-73.965332,40.801025,2,0\n",
      "19.3,2012-05-10 18:43:16 UTC,-73.954366,40.778924,-74.004094,40.723104,1,1\n",
      "7.5,2014-05-20 23:09:00 UTC,-73.999165,40.738377,-74.003473,40.723862,2,2\n",
      "12.5,2015-02-23 19:51:31 UTC,-73.9652099609375,40.76948165893555,-73.98949432373047,40.739742279052734,1,3\n",
      "10.9,2011-03-19 03:32:00 UTC,-73.99259,40.742957,-73.989908,40.711053,1,4\n",
      "7.0,2012-09-18 12:51:11 UTC,-73.971195,40.751566,-73.975922,40.756361,1,5\n",
      "19.0,2014-05-20 23:09:00 UTC,-73.998392,40.74517,-73.939845,40.74908,1,6\n",
      "8.9,2012-07-18 08:46:08 UTC,-73.997638,40.756541,-73.973303,40.762019,1,7\n",
      "4.5,2010-07-11 20:39:08 UTC,-73.976738,40.751321,-73.986671,40.74883,1,8\n",
      "7.0,2013-12-12 02:16:40 UTC,-73.985024,40.767537,-73.981273,40.779302,1,9\n",
      "\n",
      "==> data/toy_data/taxi-train.csv <==\n",
      "11.3,2011-01-28 20:42:59 UTC,-73.999022,40.739146,-73.990369,40.717866,1,0\n",
      "7.7,2011-06-27 04:28:06 UTC,-73.987443,40.729221,-73.979013,40.758641,1,1\n",
      "10.5,2011-04-03 00:54:53 UTC,-73.982539,40.735725,-73.954797,40.778388,1,2\n",
      "16.2,2009-04-10 04:11:56 UTC,-74.001945,40.740505,-73.91385,40.758559,1,3\n",
      "33.5,2014-02-24 18:22:00 UTC,-73.993372,40.753382,-73.8609,40.732897,2,4\n",
      "6.9,2011-12-10 00:25:23 UTC,-73.996237,40.721848,-73.989416,40.718052,1,5\n",
      "6.1,2012-09-01 14:30:19 UTC,-73.977048,40.758461,-73.984899,40.744693,2,6\n",
      "9.5,2012-11-08 13:28:07 UTC,-73.969402,40.757545,-73.950049,40.776079,1,7\n",
      "9.0,2014-07-15 11:37:25 UTC,-73.979318,40.760949,-73.95767,40.773724,1,8\n",
      "3.3,2009-11-09 18:06:58 UTC,-73.955675,40.779154,-73.961172,40.772368,1,9\n",
      "\n",
      "==> data/toy_data/taxi-valid.csv <==\n",
      "5.3,2012-01-03 19:21:35 UTC,-73.962627,40.763214,-73.973485,40.753353,1,0\n",
      "25.3,2010-09-27 07:30:15 UTC,-73.965799,40.794243,-73.927134,40.852261,3,1\n",
      "27.5,2015-05-19 00:40:02 UTC,-73.86344146728516,40.76899719238281,-73.96058654785156,40.76129913330078,1,2\n",
      "5.7,2010-04-29 12:28:00 UTC,-73.989255,40.738912,-73.97558,40.749172,1,3\n",
      "11.5,2013-06-23 06:08:09 UTC,-73.99731,40.763735,-73.955657,40.768141,1,4\n",
      "18.0,2014-10-14 18:52:03 UTC,-73.997995,40.761638,-74.008985,40.712442,1,5\n",
      "4.9,2010-04-29 12:28:00 UTC,-73.977315,40.766182,-73.970845,40.761462,5,6\n",
      "32.33,2014-02-24 18:22:00 UTC,-73.985358,40.761352,-73.92427,40.699145,1,7\n",
      "17.0,2015-03-26 02:48:58 UTC,-73.93981170654297,40.846473693847656,-73.97361755371094,40.786983489990234,1,8\n",
      "12.5,2013-04-09 09:39:13 UTC,-73.977323,40.753934,-74.00719,40.741472,1,9\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head data/toy_data/taxi*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use tf.data to read the CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrote these functions for reading data from the csv files above in the [previous notebook](./2a_dataset_api.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = [\n",
    "    \"fare_amount\",\n",
    "    \"pickup_datetime\",\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "    \"key\",\n",
    "]\n",
    "LABEL_COLUMN = \"fare_amount\"\n",
    "DEFAULTS = [[0.0], [\"na\"], [0.0], [0.0], [0.0], [0.0], [0.0], [\"na\"]]\n",
    "UNWANTED_COLS = [\"pickup_datetime\", \"key\"]\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    label = row_data.pop(LABEL_COLUMN)\n",
    "    features = row_data\n",
    "\n",
    "    for unwanted_col in UNWANTED_COLS:\n",
    "        features.pop(unwanted_col)\n",
    "\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def create_dataset(pattern, batch_size=1, mode=\"eval\"):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        pattern, batch_size, CSV_COLUMNS, DEFAULTS\n",
    "    )\n",
    "\n",
    "    dataset = dataset.map(features_and_labels)\n",
    "\n",
    "    if mode == \"train\":\n",
    "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
    "\n",
    "    # take advantage of multi-threading; 1=AUTOTUNE\n",
    "    dataset = dataset.prefetch(1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a simple keras DNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use feature columns to connect our raw data to our keras DNN model. Feature columns make it easy to perform common types of feature engineering on your raw data. For example, you can one-hot encode categorical data, create feature crosses, embeddings and more. We'll cover these in more detail later in the course, but if you want to a sneak peak browse the official TensorFlow [feature columns guide](https://www.tensorflow.org/guide/feature_columns).\n",
    "\n",
    "In our case we won't do any feature engineering. However, we still need to create a list of feature columns to specify the numeric values which will be passed on to our model. To do this, we use `tf.feature_column.numeric_column()`\n",
    "\n",
    "We use a python dictionary comprehension to create the feature columns for our model, which is just an elegant alternative to a for loop.\n",
    "\n",
    "**Lab Task #1:** Create a feature column dictionary that we will use when building our deep neural network below. The keys should be the element of the `INPUT_COLS` list, while the values should be numeric feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pickup_longitude': NumericColumn(key='pickup_longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " 'pickup_latitude': NumericColumn(key='pickup_latitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " 'dropoff_longitude': NumericColumn(key='dropoff_longitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " 'dropoff_latitude': NumericColumn(key='dropoff_latitude', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " 'passenger_count': NumericColumn(key='passenger_count', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_COLS = [\n",
    "    \"pickup_longitude\",\n",
    "    \"pickup_latitude\",\n",
    "    \"dropoff_longitude\",\n",
    "    \"dropoff_latitude\",\n",
    "    \"passenger_count\",\n",
    "]\n",
    "\n",
    "# Create input layer of feature columns\n",
    "# TODO 1\n",
    "# TODO -- Your code here.\n",
    "feature_columns = {\n",
    "    colname: tf.feature_column.numeric_column(colname) for colname in INPUT_COLS\n",
    "} \n",
    "\n",
    "#$my preview\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the DNN model. The Sequential model is a linear stack of layers and when building a model using the Sequential API, you configure each layer of the model in turn. Once all the layers have been added, you compile the model.\n",
    "\n",
    "**Lab Task #2a:** Create a deep neural network using Keras's Sequential API. In the cell below, use the `tf.keras.layers` library to create all the layers for your deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a keras DNN model using Sequential API\n",
    "# TODO 2a\n",
    "# TODO -- Your code here.\n",
    "model = Sequential(\n",
    "    [\n",
    "        DenseFeatures(feature_columns=feature_columns.values()),\n",
    "        Dense(units=32, activation=\"relu\", name=\"h1\"),\n",
    "        Dense(units=8, activation=\"relu\", name=\"h2\"),\n",
    "        Dense(units=1, activation=\"linear\", name=\"output\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to prepare the model for training, you must configure the learning process. This is done using the compile method. The compile method takes three arguments:\n",
    "\n",
    "* An optimizer. This could be the string identifier of an existing optimizer (such as `rmsprop` or `adagrad`), or an instance of the [Optimizer class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/optimizers).\n",
    "* A loss function. This is the objective that the model will try to minimize. It can be the string identifier of an existing loss function from the [Losses class](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses) (such as categorical_crossentropy or mse), or it can be a custom objective function.\n",
    "* A list of metrics. For any machine learning problem you will want a set of metrics to evaluate your model. A metric could be the string identifier of an existing metric or a custom metric function.\n",
    "\n",
    "We will add an additional custom metric called `rmse` to our list of metrics which will return the root mean square error.\n",
    "\n",
    "**Lab Task #2b:** Compile the model you created above. Create a custom loss function called `rmse` which computes the root mean squared error between `y_true` and `y_pred`. Pass this function to the model as an evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 2b\n",
    "# Create a custom evalution metric\n",
    "def rmse(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))# TODO -- Your code here.\n",
    "\n",
    "\n",
    "# Compile the keras model\n",
    "# TODO -- Your code here.\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train your model, Keras provides three functions that can be used:\n",
    " 1. `.fit()` for training a model for a fixed number of epochs (iterations on a dataset).\n",
    " 2. `.fit_generator()` for training a model on data yielded batch-by-batch by a generator\n",
    " 3. `.train_on_batch()` runs a single gradient update on a single batch of data. \n",
    " \n",
    "The `.fit()` function works well for small datasets which can fit entirely in memory. However, for large datasets (or if you need to manipulate the training data on the fly via data augmentation, etc) you will need to use `.fit_generator()` instead. The `.train_on_batch()` method is for more fine-grained control over training and accepts only a single batch of data.\n",
    "\n",
    "The taxifare dataset we sampled is small enough to fit in memory, so can we could use `.fit` to train our model. Our `create_dataset` function above generates batches of training examples, so we could also use `.fit_generator`. In fact, when calling `.fit` the method inspects the data, and if it's a generator (as our dataset is) it will invoke automatically `.fit_generator` for training. \n",
    "\n",
    "We start by setting up some parameters for our training job and create the data generators for the training and validation data.\n",
    "\n",
    "We refer you the the blog post [ML Design Pattern #3: Virtual Epochs](https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730) for further details on why express the training in terms of `NUM_TRAIN_EXAMPLES` and `NUM_EVALS` and why, in this training code, the number of epochs is really equal to the number of evaluations we perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 1000\n",
    "NUM_TRAIN_EXAMPLES = 10000 * 5  # training dataset will repeat, wrap around\n",
    "NUM_EVALS = 50  # how many times to evaluate\n",
    "NUM_EVAL_EXAMPLES = 10000  # enough to get a reasonable sample\n",
    "\n",
    "trainds = create_dataset(\n",
    "    pattern=\"data/toy_data/taxi-train*\", batch_size=TRAIN_BATCH_SIZE, mode=\"train\" #$my\n",
    ")\n",
    "\n",
    "evalds = create_dataset(\n",
    "    pattern=\"data/toy_data/taxi-valid*\", batch_size=1000, mode=\"eval\" #$my\n",
    ").take(NUM_EVAL_EXAMPLES // 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various arguments you can set when calling the [.fit method](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Model#fit). Here `x` specifies the input data which in our case is a `tf.data` dataset returning a tuple of (inputs, targets). The `steps_per_epoch` parameter is used to mark the end of training for a single epoch. Here we are training for NUM_EVALS epochs. Lastly, for the `callback` argument we specify a Tensorboard callback so we can inspect Tensorboard after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab Task #3:** In the cell below, you will train your model. First, define the `steps_per_epoch` then train your model using `.fit()`, saving the model training output to a variable called `history`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "1/1 [==============================] - ETA: 0s - loss: 1018.5985 - rmse: 31.9155 - mse: 1018.5985WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'ExpandDims_4:0' shape=(1000, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'ExpandDims_3:0' shape=(1000, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'ExpandDims_1:0' shape=(1000, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'ExpandDims:0' shape=(1000, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'ExpandDims_2:0' shape=(1000, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "1/1 [==============================] - 16s 16s/step - loss: 1018.5985 - rmse: 31.9155 - mse: 1018.5985 - val_loss: 894.0502 - val_rmse: 29.9005 - val_mse: 894.0502\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 599ms/step - loss: 925.4343 - rmse: 30.4210 - mse: 925.4343 - val_loss: 801.3946 - val_rmse: 28.3087 - val_mse: 801.3946\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 394ms/step - loss: 813.0885 - rmse: 28.5147 - mse: 813.0885 - val_loss: 715.3589 - val_rmse: 26.7461 - val_mse: 715.3589\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 404ms/step - loss: 708.5370 - rmse: 26.6184 - mse: 708.5370 - val_loss: 636.5344 - val_rmse: 25.2295 - val_mse: 636.5344\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 639.1967 - rmse: 25.2823 - mse: 639.1967 - val_loss: 562.3658 - val_rmse: 23.7140 - val_mse: 562.3658\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 385ms/step - loss: 576.1441 - rmse: 24.0030 - mse: 576.1441 - val_loss: 495.4537 - val_rmse: 22.2586 - val_mse: 495.4537\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 448ms/step - loss: 503.6366 - rmse: 22.4419 - mse: 503.6366 - val_loss: 434.6843 - val_rmse: 20.8488 - val_mse: 434.6843\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 499ms/step - loss: 444.2299 - rmse: 21.0768 - mse: 444.2299 - val_loss: 379.3983 - val_rmse: 19.4781 - val_mse: 379.3983\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 397.6841 - rmse: 19.9420 - mse: 397.6841 - val_loss: 330.5111 - val_rmse: 18.1798 - val_mse: 330.5111\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 337.7860 - rmse: 18.3790 - mse: 337.7860 - val_loss: 286.9388 - val_rmse: 16.9390 - val_mse: 286.9388\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 294.0153 - rmse: 17.1469 - mse: 294.0153 - val_loss: 249.3327 - val_rmse: 15.7898 - val_mse: 249.3327\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 246.8798 - rmse: 15.7124 - mse: 246.8798 - val_loss: 216.1212 - val_rmse: 14.7008 - val_mse: 216.1212\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 233.6236 - rmse: 15.2848 - mse: 233.6236 - val_loss: 191.0991 - val_rmse: 13.8225 - val_mse: 191.0991\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 191.7903 - rmse: 13.8488 - mse: 191.7903 - val_loss: 169.8796 - val_rmse: 13.0333 - val_mse: 169.8796\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 171.8182 - rmse: 13.1079 - mse: 171.8182 - val_loss: 152.5815 - val_rmse: 12.3515 - val_mse: 152.5815\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 161.3919 - rmse: 12.7040 - mse: 161.3919 - val_loss: 136.8915 - val_rmse: 11.6986 - val_mse: 136.8915\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 298ms/step - loss: 126.8981 - rmse: 11.2649 - mse: 126.8981 - val_loss: 125.3424 - val_rmse: 11.1920 - val_mse: 125.3424\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 103.8192 - rmse: 10.1892 - mse: 103.8192 - val_loss: 116.5881 - val_rmse: 10.7960 - val_mse: 116.5881\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 95.8670 - rmse: 9.7912 - mse: 95.8670 - val_loss: 112.0715 - val_rmse: 10.5843 - val_mse: 112.0715\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 103.9606 - rmse: 10.1961 - mse: 103.9606 - val_loss: 108.9511 - val_rmse: 10.4327 - val_mse: 108.9511\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 295ms/step - loss: 108.6009 - rmse: 10.4212 - mse: 108.6009 - val_loss: 106.4649 - val_rmse: 10.3150 - val_mse: 106.4649\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 286ms/step - loss: 110.5544 - rmse: 10.5145 - mse: 110.5544 - val_loss: 105.1799 - val_rmse: 10.2525 - val_mse: 105.1799\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 291ms/step - loss: 107.0119 - rmse: 10.3447 - mse: 107.0119 - val_loss: 103.2631 - val_rmse: 10.1571 - val_mse: 103.2631\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 88.1851 - rmse: 9.3907 - mse: 88.1851 - val_loss: 101.9262 - val_rmse: 10.0931 - val_mse: 101.9262\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 356ms/step - loss: 86.0957 - rmse: 9.2788 - mse: 86.0957 - val_loss: 100.9976 - val_rmse: 10.0479 - val_mse: 100.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50\n",
      "1/1 [==============================] - 1s 524ms/step - loss: 79.8418 - rmse: 8.9354 - mse: 79.8418 - val_loss: 100.0117 - val_rmse: 9.9945 - val_mse: 100.0117\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 81.2728 - rmse: 9.0151 - mse: 81.2728 - val_loss: 99.2418 - val_rmse: 9.9608 - val_mse: 99.2418\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 94.4518 - rmse: 9.7186 - mse: 94.4518 - val_loss: 99.9241 - val_rmse: 9.9920 - val_mse: 99.9241\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 83.5743 - rmse: 9.1419 - mse: 83.5743 - val_loss: 99.5089 - val_rmse: 9.9746 - val_mse: 99.5089\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 279ms/step - loss: 98.4221 - rmse: 9.9208 - mse: 98.4221 - val_loss: 100.0939 - val_rmse: 10.0010 - val_mse: 100.0939\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 88.5575 - rmse: 9.4105 - mse: 88.5575 - val_loss: 98.8365 - val_rmse: 9.9377 - val_mse: 98.8365\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 88.1806 - rmse: 9.3905 - mse: 88.1806 - val_loss: 99.4884 - val_rmse: 9.9692 - val_mse: 99.4884\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 74.2524 - rmse: 8.6170 - mse: 74.2524 - val_loss: 98.8932 - val_rmse: 9.9374 - val_mse: 98.8932\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 100.9857 - rmse: 10.0492 - mse: 100.9857 - val_loss: 100.8807 - val_rmse: 10.0327 - val_mse: 100.8807\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 270ms/step - loss: 89.2088 - rmse: 9.4450 - mse: 89.2088 - val_loss: 101.0557 - val_rmse: 10.0443 - val_mse: 101.0557\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 78.3940 - rmse: 8.8540 - mse: 78.3940 - val_loss: 100.8385 - val_rmse: 10.0304 - val_mse: 100.8385\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 274ms/step - loss: 92.3226 - rmse: 9.6085 - mse: 92.3226 - val_loss: 100.2980 - val_rmse: 10.0069 - val_mse: 100.2980\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 74.8739 - rmse: 8.6530 - mse: 74.8739 - val_loss: 101.2246 - val_rmse: 10.0583 - val_mse: 101.2246\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 98.2681 - rmse: 9.9130 - mse: 98.2681 - val_loss: 100.5564 - val_rmse: 10.0239 - val_mse: 100.5564\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 84.2589 - rmse: 9.1793 - mse: 84.2589 - val_loss: 101.0707 - val_rmse: 10.0482 - val_mse: 101.0707\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 103.3811 - rmse: 10.1676 - mse: 103.3811 - val_loss: 101.2232 - val_rmse: 10.0564 - val_mse: 101.2232\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 85.8734 - rmse: 9.2668 - mse: 85.8734 - val_loss: 101.2812 - val_rmse: 10.0521 - val_mse: 101.2812\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 86.5647 - rmse: 9.3040 - mse: 86.5647 - val_loss: 102.2591 - val_rmse: 10.1094 - val_mse: 102.2591\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 85.3371 - rmse: 9.2378 - mse: 85.3371 - val_loss: 102.1211 - val_rmse: 10.1029 - val_mse: 102.1211\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 481ms/step - loss: 79.8052 - rmse: 8.9334 - mse: 79.8052 - val_loss: 102.3121 - val_rmse: 10.1127 - val_mse: 102.3121\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 72.3604 - rmse: 8.5065 - mse: 72.3604 - val_loss: 101.5088 - val_rmse: 10.0668 - val_mse: 101.5088\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 85.4161 - rmse: 9.2421 - mse: 85.4161 - val_loss: 101.6290 - val_rmse: 10.0798 - val_mse: 101.6290\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 101.5074 - rmse: 10.0751 - mse: 101.5074 - val_loss: 102.0756 - val_rmse: 10.0989 - val_mse: 102.0756\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 80.0130 - rmse: 8.9450 - mse: 80.0130 - val_loss: 101.8721 - val_rmse: 10.0886 - val_mse: 101.8721\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 71.0012 - rmse: 8.4262 - mse: 71.0012 - val_loss: 102.0178 - val_rmse: 10.0959 - val_mse: 102.0178\n"
     ]
    }
   ],
   "source": [
    "# TODO 3\n",
    "%time \n",
    "steps_per_epoch = NUM_TRAIN_EXAMPLES // (TRAIN_BATCH_SIZE * NUM_EVALS) # TODO -- Your code here. \n",
    "\n",
    "LOGDIR = \"./logs/taxi_trained\" #$my\n",
    "\n",
    "# TODO -- Your code here. \n",
    "history = model.fit(\n",
    "    x=trainds,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=NUM_EVALS,\n",
    "    validation_data=evalds,\n",
    "    callbacks=[TensorBoard(LOGDIR)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-level model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've run data through the model, we can call `.summary()` on the model to get a high-level summary of our network. We can also plot the training and evaluation curves for the metrics we computed above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_features (DenseFeature multiple                  0         \n",
      "_________________________________________________________________\n",
      "h1 (Dense)                   multiple                  192       \n",
      "_________________________________________________________________\n",
      "h2 (Dense)                   multiple                  264       \n",
      "_________________________________________________________________\n",
      "output (Dense)               multiple                  9         \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `.fit` (or `.fit_generator`) returns a History object which collects all the events recorded during training. Similar to Tensorboard, we can plot the training and validation curves for the model loss and rmse by accessing these elements of the History object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2620cf618c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_COLS = [\"rmse\", \"val_rmse\"]\n",
    "\n",
    "pd.DataFrame(history.history)[RMSE_COLS].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2620e2cd948>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOSS_COLS = [\"loss\", \"val_loss\"]\n",
    "\n",
    "pd.DataFrame(history.history)[LOSS_COLS].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions with our trained model, we can call the [predict method](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict), passing to it a dictionary of values. The `steps` parameter determines the total number of steps before declaring the prediction round finished. Here since we have just one example, we set `steps=1` (setting `steps=None` would also work). Note, however, that if x is a `tf.data` dataset or a dataset iterator, and steps is set to None, predict will run until the input dataset is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'pickup_longitude': <tf.Tensor 'ExpandDims_4:0' shape=(1, 1) dtype=float32>, 'pickup_latitude': <tf.Tensor 'ExpandDims_3:0' shape=(1, 1) dtype=float32>, 'dropoff_longitude': <tf.Tensor 'ExpandDims_1:0' shape=(1, 1) dtype=float32>, 'dropoff_latitude': <tf.Tensor 'ExpandDims:0' shape=(1, 1) dtype=float32>, 'passenger_count': <tf.Tensor 'ExpandDims_2:0' shape=(1, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'pickup_longitude': <tf.Tensor 'ExpandDims_4:0' shape=(1, 1) dtype=float32>, 'pickup_latitude': <tf.Tensor 'ExpandDims_3:0' shape=(1, 1) dtype=float32>, 'dropoff_longitude': <tf.Tensor 'ExpandDims_1:0' shape=(1, 1) dtype=float32>, 'dropoff_latitude': <tf.Tensor 'ExpandDims:0' shape=(1, 1) dtype=float32>, 'passenger_count': <tf.Tensor 'ExpandDims_2:0' shape=(1, 1) dtype=float32>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.786621]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(\n",
    "    x={\n",
    "        \"pickup_longitude\": tf.convert_to_tensor([-73.982683]),\n",
    "        \"pickup_latitude\": tf.convert_to_tensor([40.742104]),\n",
    "        \"dropoff_longitude\": tf.convert_to_tensor([-73.983766]),\n",
    "        \"dropoff_latitude\": tf.convert_to_tensor([40.755174]),\n",
    "        \"passenger_count\": tf.convert_to_tensor([3.0]),\n",
    "    },\n",
    "    steps=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export and deploy our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, making individual predictions is not realistic, because we can't expect client code to have a model object in memory. For others to use our trained model, we'll have to export our model to a file, and expect client code to instantiate the model from that exported file. \n",
    "\n",
    "We'll export the model to a TensorFlow SavedModel format. Once we have a model in this format, we have lots of ways to \"serve\" the model, from a web application, from JavaScript, from mobile applications, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs_4:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs_3:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs_1:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs_2:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs/passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs/passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs/passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'inputs/pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'inputs/pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'inputs/dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'inputs/dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'inputs/passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'collections.OrderedDict'> input: OrderedDict([('pickup_longitude', <tf.Tensor 'pickup_longitude:0' shape=(None, 1) dtype=float32>), ('pickup_latitude', <tf.Tensor 'pickup_latitude:0' shape=(None, 1) dtype=float32>), ('dropoff_longitude', <tf.Tensor 'dropoff_longitude:0' shape=(None, 1) dtype=float32>), ('dropoff_latitude', <tf.Tensor 'dropoff_latitude:0' shape=(None, 1) dtype=float32>), ('passenger_count', <tf.Tensor 'passenger_count:0' shape=(None, 1) dtype=float32>)])\n",
      "Consider rewriting this model with the Functional API.\n",
      "INFO:tensorflow:Assets written to: ./export/savedmodel\\20220329114538\\assets\n",
      "INFO:tensorflow:Assets written to: ./export/savedmodel\\20220329114538\\assets\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"./export/savedmodel\"\n",
    "shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "EXPORT_PATH = os.path.join(OUTPUT_DIR, TIMESTAMP)\n",
    "\n",
    "tf.saved_model.save(model, EXPORT_PATH)  # with default serving function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['dropoff_latitude'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_dropoff_latitude:0\n",
      "  inputs['dropoff_longitude'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_dropoff_longitude:0\n",
      "  inputs['passenger_count'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_passenger_count:0\n",
      "  inputs['pickup_latitude'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_pickup_latitude:0\n",
      "  inputs['pickup_longitude'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_pickup_longitude:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['output_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-29 11:45:43.460791: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-03-29 11:45:43.461277: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "FIND: Parameter format not correct\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default \\\n",
    "    --dir {EXPORT_PATH}\n",
    "\n",
    "!find {EXPORT_PATH}\n",
    "os.environ['EXPORT_PATH'] = EXPORT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mystop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-255d8eb4da7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmystop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'mystop' is not defined"
     ]
    }
   ],
   "source": [
    "mystop\n",
    "#stop here - the rest wouldn't work outside of GCP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy our model to Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will deploy our trained model to Vertex AI and see how we can make online predicitons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "flake8-noqa-line-1",
     "flake8-noqa-line-8-E501"
    ]
   },
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "PROJECT = PROJECT[0]\n",
    "BUCKET = PROJECT\n",
    "REGION = \"us-central1\"\n",
    "MODEL_DISPLAYNAME = f\"taxifare-kerase-sequential{TIMESTAMP}\"\n",
    "\n",
    "print(f\"MODEL_DISPLAYNAME: {MODEL_DISPLAYNAME}\")\n",
    "\n",
    "# from https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "SERVING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest\"\n",
    ")\n",
    "\n",
    "os.environ[\"BUCKET\"] = BUCKET\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create GCS bucket if it doesn't exist already...\n",
    "exists=$(gsutil ls -d | grep -w gs://${BUCKET}/)\n",
    "\n",
    "if [ -n \"$exists\" ]; then\n",
    "    echo -e \"Bucket exists, let's not recreate it.\"\n",
    "else\n",
    "    echo \"Creating a new GCS bucket.\"\n",
    "    gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "    echo \"\\nHere are your current buckets:\"\n",
    "    gsutil ls\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "flake8-noqa-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!gsutil cp -R $EXPORT_PATH gs://$BUCKET/$MODEL_DISPLAYNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_model = aiplatform.Model.upload(\n",
    "    display_name=MODEL_DISPLAYNAME,\n",
    "    artifact_uri=f\"gs://{BUCKET}/{MODEL_DISPLAYNAME}\",\n",
    "    serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "\n",
    "endpoint = uploaded_model.deploy(\n",
    "    machine_type=MACHINE_TYPE,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='assets/taxi_fare_keras_seq_model.png' width='80%'>\n",
    "<sup>(image:Your model in Vertex AI)</sup>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = {\n",
    "    \"pickup_longitude\": -73.982683,\n",
    "    \"pickup_latitude\": 40.742104,\n",
    "    \"dropoff_longitude\": -73.983766,\n",
    "    \"dropoff_latitude\": 40.755174,\n",
    "    \"passenger_count\": 3.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.predict([instance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "\n",
    "When deploying a model to an endpoint for online prediction, the minimum `min-replica-count` is 1, and it is charged per node hour. So let's delete the endpoint to reduce unnecessary charges. Before we can delete the endpoint, we first undeploy all attached models... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2021 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m90"
  },
  "kernelspec": {
   "display_name": "anya_tf2",
   "language": "python",
   "name": "anya_tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
