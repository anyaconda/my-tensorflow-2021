{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0e7c4012-7071-4f22-b589-28384115989b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta 8/29/2022 Introducing TensorFlow Similarity\n",
    "# Example from blog post by Elie Bursztein and Owen Vallis, Google 20210913\n",
    "#Refer to https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html\n",
    "\n",
    "#infra: WGClouud\n",
    "#kernel: pre-built TensorFlow 2 (local)\n",
    "#$note: python 3.7.12 \n",
    "# numpy 1.21.6\n",
    "# tf2 2.9.1, tensorflow_similarity 0.16.7, tabulate 0.8.10\n",
    "\n",
    "\n",
    "#history\n",
    "# 8/29/2022 BUILD TF SIMILARITY MODEL WITH IMAGES\n",
    "#      ds a sample from MNIST\n",
    "#      $xtra: display an image with PIL\n",
    "#      Since images are just an array of pixels carrying various color codes. NumPy can be used to convert an array into image.\n",
    "\n",
    "\n",
    "#References\n",
    "#TensorFlow Similarity Supervised Learning Hello World\n",
    "# Refer to https://github.com/tensorflow/similarity/blob/master/examples/supervised_hello_world.ipynb\n",
    "\n",
    "#Convert a NumPy array to an image  \n",
    "# Refer to https://www.geeksforgeeks.org/convert-a-numpy-array-to-an-image/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daed7818-aa8f-42e1-8e51-3bc9c90e4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your CPU supports instructions that this binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2\n",
      "For maximum performance, you can install NMSLIB from sources \n",
      "pip install --no-binary :all: nmslib\n"
     ]
    }
   ],
   "source": [
    "#$error: ModuleNotFoundError: No module named 'tabulate'\n",
    "#$fix: inserted cell above\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "try:\n",
    "    # Embedding output layer with L2 norm\n",
    "    from tensorflow_similarity.layers import MetricEmbedding \n",
    "    # Specialized metric loss\n",
    "    from tensorflow_similarity.losses import MultiSimilarityLoss \n",
    "    # Sub classed keras Model with support for indexing\n",
    "    from tensorflow_similarity.models import SimilarityModel\n",
    "    # Data sampler that pulls datasets directly from tf dataset catalog\n",
    "    from tensorflow_similarity.samplers import TFDatasetMultiShotMemorySampler\n",
    "    # Nearest neighbor visualizer\n",
    "    from tensorflow_similarity.visualization import viz_neigbors_imgs\n",
    "except ModuleNotFoundError:\n",
    "    #$note initially needed to install tf similarity\n",
    "    #!pip install tensorflow_similarity\n",
    "    !pip install tabulate\n",
    "    \n",
    "    # Embedding output layer with L2 norm\n",
    "    from tensorflow_similarity.layers import MetricEmbedding \n",
    "    # Specialized metric loss\n",
    "    from tensorflow_similarity.losses import MultiSimilarityLoss \n",
    "    # Sub classed keras Model with support for indexing\n",
    "    from tensorflow_similarity.models import SimilarityModel\n",
    "    # Data sampler that pulls datasets directly from tf dataset catalog\n",
    "    from tensorflow_similarity.samplers import TFDatasetMultiShotMemorySampler\n",
    "    # Nearest neighbor visualizer\n",
    "    from tensorflow_similarity.visualization import viz_neigbors_imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3daeaf1e-a6cb-4c10-b3e6-28fb69d2e0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:53) \n",
      "[GCC 9.4.0]\n"
     ]
    }
   ],
   "source": [
    "#python version $my\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "490e529b-6b3d-42e9-bd25-01c1c87b8d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.9.1\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.7/site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: explainable-ai-sdk, tensorflow-cloud, tensorflow-serving-api, tensorflow-transform, tfx-bsl, witwidget\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5374765b-b512-4f4c-b6f1-83513df0799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow-similarity\n",
      "Version: 0.16.7\n",
      "Summary: Metric Learning for Humans\n",
      "Home-page: https://github.com/tensorflow/similarity\n",
      "Author: Tensorflow Similarity authors\n",
      "Author-email: tf-similarity@google.com\n",
      "License: Apache License 2.0\n",
      "Location: /home/jupyter/.local/lib/python3.7/site-packages\n",
      "Requires: bokeh, distinctipy, matplotlib, nmslib, numpy, pandas, Pillow, tabulate, tensorflow-datasets, tqdm, umap-learn\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a53695-b467-476c-a07f-c5e466884962",
   "metadata": {},
   "source": [
    "# Introducing TensorFlow Similarity\n",
    "Refer to https://blog.tensorflow.org/2021/09/introducing-tensorflow-similarity.html\n",
    "\n",
    "<a href=\"https://github.com/tensorflow/similarity\">TensorFlow Similarity</a> - a python package designed to make it easy and fast to train similarity models using TensorFlow.\n",
    "\n",
    "## 0.Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5346f6b1-39a7-4630-831a-e49e9103d48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 17:01:46.272371: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-08-29 17:01:46.272431: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-29 17:01:46.272494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fbf47b419da0): /proc/driver/nvidia/version does not exist\n",
      "2022-08-29 17:01:46.302254: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d45e7a64f354f2287a545f67a3a7852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "converting train:   0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe0b24e25c14f80930d0c809c54dcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "converting test:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The initial batch size is 20 (10 classes * 2 examples per class) with 0 augmenters\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3401e255920546a897e914577479a29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "filtering examples:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4ee5d3c0a84460acddba2478956cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "selecting classes:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55965b402773414eb56477b650ef2661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "gather examples:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8193e7de1c44f5a920378f5914a6ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "indexing classes:   0%|          | 0/70000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data sampler that generates balanced batches from MNIST dataset\n",
    "from tensorflow_similarity.samplers import TFDatasetMultiShotMemorySampler\n",
    "sampler = TFDatasetMultiShotMemorySampler(dataset_name='mnist', classes_per_batch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c0b516-b7e7-4f39-8c05-040af64d23f2",
   "metadata": {},
   "source": [
    "### 0.1 View an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3496214b-32f9-49c7-b80e-6688e93b4dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1) (1,)\n",
      "(28, 28, 1) ()\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "qx, qy = sampler.get_slice(3737, 1)\n",
    "\n",
    "#myPreview\n",
    "#qx class numpy.ndarray [of numpy.ndarrays], qy class numpy.ndarray\n",
    "print(qx.shape, qy.shape) \n",
    "#qx[0] class numpy.ndarray, qy[0] numpy.int64\n",
    "print(qx[0].shape, qy[0].shape)\n",
    "\n",
    "#Reshape the above array to suitable dimensions\n",
    "print(qx[0].reshape(28,28).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50550e47-0f1a-435b-833d-840075cf884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "<class 'PIL.Image.Image'>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA20lEQVR4nGNgGI6AkbXgw79///9tnsoGFWGBy2lXRf5b/pGPgcHA610tmj7e6//+1UGYry6yokku/fdvMR9U8hEHqhz79X+fFCBM/R/boYJMUDpInWH9AwjThO0Omqnb//3zhTIv/VNG1cnExfDwAFRI+PtrNLf+++cPZRr83I1mKvuBrdxQ5op/mWiSDMwwOYaH/0TRJeFA/xdCkgldMonlpBAujTxP/yXp45JM/vfvjDAuYy0YGKa9x6Xz5r9/krjkZD/8W4vhRhhI+ffPGpccg82nfVw4JVEBAHhoRglAKK5kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image as im\n",
    "\n",
    "# Create an image object from the above array using PIL library\n",
    "data = im.fromarray(qx[0].reshape(28,28))\n",
    "print(qy[0])\n",
    "print(data.__class__)\n",
    "data\n",
    "\n",
    "# saving the final output as a PNG file\n",
    "#data.save('image.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ed4c4-c1d5-4717-b13f-318083439092",
   "metadata": {},
   "source": [
    "## 1. Data Prep\n",
    "Data is already well pr\n",
    "## 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109102d1-8308-4852-8c3f-6ecb6a29f1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance metric automatically set to cosine use the distance arg to override.\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 24s 20ms/step - loss: 0.1394\n",
      "Warmup complete\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0534\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0378\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0322\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 0.0287\n",
      "[Indexing 100 points]\n",
      "|-Computing embeddings\n",
      "4/4 [==============================] - 0s 6ms/step\n",
      "|-Storing data points in key value store\n",
      "|-Adding embeddings to index.\n",
      "|-Building index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0%   10   20   30   40   50   60   70   80   90   100%\n",
      "|----|----|----|----|----|----|----|----|----|----|\n",
      "***************************************************\n"
     ]
    }
   ],
   "source": [
    "# Build a Similarity model using standard Keras layers\n",
    "inputs = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Rescaling(1/255)(inputs)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "outputs = MetricEmbedding(64)(x)\n",
    "\n",
    "# Build a specialized Similarity model\n",
    "model = SimilarityModel(inputs, outputs)\n",
    "\n",
    "# Train Similarity model using contrastive loss\n",
    "model.compile('adam', loss=MultiSimilarityLoss())\n",
    "model.fit(sampler, epochs=5)\n",
    "\n",
    "# Index 100 embedded MNIST examples to make them searchable\n",
    "sx, sy = sampler.get_slice(0,100)\n",
    "model.index(x=sx, y=sy, data=sx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac49447-b012-46e7-af00-465e454d2172",
   "metadata": {},
   "source": [
    "## 3. Query Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "046a0e0b-a525-4900-b105-ddb7c7b4af91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "# Find the top 5 most similar indexed MNIST examples for a given example\n",
    "qx, qy = sampler.get_slice(3737, 1)\n",
    "nns = model.single_lookup(qx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "328260e6-8926-4dbc-981a-1b0276815b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABU0AAADhCAYAAAD8gJRnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh4UlEQVR4nO3deZRcZZk/8OdNd9LZSAhBwhbZE5AdEQIBQUUYN9yVEQcQZRFxjuNy1Jnx5zLMqOhxBxVFwVGcARcUEBdERCDs64RNlkASCJskQEhCuvv+/qjK8TXW23RXd6eq05/POXWSvN9+730q6Tf31tP3VqWqqgIAAAAAgJoxrS4AAAAAAKCdaJoCAAAAAGQ0TQEAAAAAMpqmAAAAAAAZTVMAAAAAgIymKQAAAABARtMUAAAAACCjadrmUkrPrPXoSSl9vdV1QSsN9bpIKe2RUrohpfRs/dc9+vjat6WUrqp/7WVrZQc2qK1KKb05+5ptU0oXppSeTik9nlI6tT7elVI6M6X0QD27KaX0qrW2PzGldHp93rKU0uXNPmcYai1el19MKf25vnbuTCkdNZBtpZT+JaW0pL6uvpdS6sqynVJKl9aze1JKb1xr7ttSSnfU9317SukNzT5nGEojdU2mlI6p15rXfnCWn5xSuj6ltCqldNZa2x2XUvpJSmlB/fh7cEAbafN1eUZK6a6UUm9K6ZgG8xuew2b5EfXj4fKU0r0ppQMbbOOT9bV5SLPPGYZau67LlNLGKaUrU0pPpJSWppTmpZTmZvkR9TW7LKX0aErp7JTSlCz/YUrp4ZTSUymlu1NK71lr36+o7/PZlNIfUkpbNfuc12eapm2uqqrJax4RMSMiVkTEeS0uC1pqKNdFSmlcRPwiIn4YEdMi4uyI+EV9vJG/RMRXIuJzDer601q1vTYinomIX2f7+l1EXBoRm0bElvX9RkR0RsTCiDgoIqZGxCci4tyU0tbZLs6IiI0iYqf6r//SzHOG4dDidbk8Il4XtbVzdER8NaW0f3+2lVI6LCI+FhGviIitI2LbiPh0Peusz70wamvu+Ij4YUppVj3for7dD0bElIj4SESck1LapJnnDUNppK7Junl5/VVVXZZlD0XEKRHxvcK+r4iId0bEkgE/URhm7bou626JiJMi4sbCvkrnsJFSemVEfD4i3hURG0TESyPivrW2sV1EvCUiHh7gU4Vh1cbr8pmIODYiXlDf1ucj4oL6+WlExJURMbeqqqlRO3/tjNrxcY3PRsTWVVVNiYjDI+KUlNKL63VuHBE/i9przo0i4vqI+N9mnvP6TtN0ZHlLRDwaEX9qdSHQRga7Lg6O2gHmK1VVraqq6msRkSLi5Y2+uKqqS6qqOjdqL9qez9ER8ZOqqpbX/3xMRDxUVdWXqqpaXlXVyqqqbq1vd3lVVZ+qqmpBVVW9VVVdGBH3R8SaA9vsqB3sjq+q6rGqqnqqqrqhyecMw21dr8tPVlV1Z33tXFPf73793NbREXFmVVXzq6p6MiL+I2prNSJix4jYPCK+XF9zl0btBPWf6vmWEbG0qqqLq5qLonbyu12TzxuGy0hak32qqupnVVWdHxFPNMieq6rqK1VVXRERPQN5gtAC7bQuo6qq06qq+n1ErGww/ZgonMPWfToiPlNV1dX17S+uqmrxWtv4RkR8NCKea+7pwjrRNuuyvs7uqqqqt76Nnqg1Tzeq5wurqno821xPRGyfbXt+VVWr1vyx/lhzjvqmiJhfVdV5VVWtjIhPRcTuKaUdm3ze6y1N05Hl6Ij4QVVVVasLgTYy2HWxc0Tcutb8W+vjTUspTYzaQffsbHhORCxIKV1cv63pspTSroX5MyJiVkTMrw/tGxEPRMSn63NvS9lt/9BmWrYuU0oTIuIl8de183zb2jlqV9escUtEzEgpTY/aCerf7SIidqn//vqIuCOldHhKqSPVbs1fVd8+tJORtCYjIvasH+vuTil9IruqBtYn7bQun0/xHDal1BERe0fEC1LtbWwWpZS+Ud/Hmv29NSKeq6rqV/3cH7RK263LlNKtUfthxi8j4rtVVT2aZQeklJZFxNMR8eao3RGZzz09pfRsRNwZtau816zBvzn/rV/kc29/6hxtNE1HiJTSC6N22+7Zz/e1MFoM0bqYHBHL1hpbFrVbiwbjzRHxeET8MRvbMiKOiIivRe3qtYuiwe0aKaWxEfGjiDi7qqo7s7m71GvbPCJOjoizU0o7DbJOGFJtsC6/FbWTwN/0c1tr52t+v0HUTjAfjYiPpJTGppQOjdpzmxgRUVVVT0T8ICLOiVqz9JyIOCG7uhxabgSuycujdrzbJGrH0n+M2ltfwHqjDdfl8+nrHHZGRIyN2sUCB0bEHhGxZ0T8e0RESmlyRPxXRHygn/uClmjXdVlV1W5Rexuod0TtLWjy7Ir67flbRsQXImLBWvlJ9X0fGLXb8ddceTpcr4HXO5qmI8dREXFFVVX3t7oQaCPPuy5SSvPTX9/U++/ekD5q7xUzZa2xKVH7ad1gNPop5Yp6vRdXVfVcRHwxIqZH7T1K19Q7JiL+O2q3Lp281tzVEXFK/fbDP0bEHyLi0EHWCUOtZesypfSFqDVb3patvefb1tr5mt8/XVXV6oh4Q0S8Jmrvj/ihiDg3IhbV93dIRJwatVuxxkXtRPu7qY83/IcWGFFrsqqq+6qqur9+q+JtEfGZqDVjYH3Sbuvy+fR1Drui/jVfr6rq4frtwl+KiFfXxz8dEf/tdSwjQNuuy/qt+j+OiI+llHZvkC+O2udo/E+DrKf+tjVbRsR7B1PnaKRpOnIcFa4yhbU977qoqmrn6q9v7t3ovWnmR8RuKaX8Ntzdov+3K/2dlNLMqDVRfrBWdGvU3kumNC9FxJlR+4n9m+sNm3wujAQtWZcppU9HxKsi4tCqqp4awLbmR0R+8rl7RDxSVdUT9VpvrarqoKqqpldVdVjU3mj/2vrX7hERl1dVdX29wXNdRFwTET4VmHYy0tbk35UXjd8qA0aydluXz6d4DlvV3g98USmP2gct/nNKaUlKaUlEzIzah51+dAD7h3VhJKzLsVE7F22kM/p+X/08/5vz35TSpHrW9Gvg9ZWm6QhQ//S0LaLJT3CD9dEQrovLovam2f+cUupKKa25uvPSwn47Ukrjo3bQGZNSGl+/nT73TxFxVVVV9641/sOImJNSOqT+/k8fiNot/HfU829G7Sf2r6uqasVacy+PiAcj4uMppc6U0tyoNWb7e1sVDLsWrsuPR+2WpVeuaXYOYFs/iIh3p5RelFKaFrXbCc/Ktr1bfZ1PTCl9OCI2y/LrIuLANVeWppT2jNrtT37IQVsYiWsypfSqVHtf70i1D6T4RNQ+iXjNtjvrx+GOiOior8/OLO+q5xER4+q5pitto03XZaSUxtXXToqIsfW1s6Zf8HznsN+PiPenlDapH0s/EBEX1rNXRO0Kuj3qj4ci4oSIOK25pw1Drx3XZUppTqq9Z+m4lNKE+g8aZkTtB/SRUjoypfTCVLNVRPxnRPy+nm2SUjoipTS5/vr1sKi93c2aOn4eEbuklN5cX/f/L2rvxXpn8LeqqvJo80dEfDtqtzS0vBYPj3Z5DOW6iNr7Lt0QtduLboyIPbPsyKh9suCaPx8Tf/30wTWPs9ba3p0R8e7Cvt4UEfdExFNRO6juXB/fqr6tlVG7XWLN48hs7s4RMS9qn859e0S8sdX/Dh4e+aOF67KK2ns05WvnX/uzrXr+wYh4pL4uvx8RXVn2hYh4sr7NiyNi+7Xmnlxf009HxH0R8aFW/zt4eKx5jMQ1GbXbfh+pH+vui9rt+WOz/FMNjsOfyvIFDfKtW/1v4eGx5tHG6/KyBmvn4CxveA5bz8ZGxOkRsTRqb2fztYgYX6h5QUQc0up/Bw+P/NGO6zJqb/t0S/0c8y9R+6yMl2Zz/zNqV3kvr/96RkRMr2cvqH/90vqavS0ijlurzkOi9rp1RX1Nb93qf4d2fKT6XxYAAAAAAOH2fAAAAACAv6FpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAynQP54nGpqxofk4arFmhbK2N5PFetSq2uY23WJKPZ0/Hk41VVvaDVdazNumS0cqyE9uNYCe2lXY+VEdYlo1df63JATdPxMSn2Ta8YmqpgBLmm+n2rS2jImmQ0u6T6yQOtrqER65LRyrES2o9jJbSXdj1WRliXjF59rUu35wMAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAINPZ6gIAAAAAYDh07Dy7mN113LRidudbT2s4fvzCg4tzrrlo12J2/BG/Kmbv2/De8rwm99eMfV9zWzGb/81ditm0s+cNaR3twpWmAAAAAAAZTVMAAAAAgIymKQAAAABARtMUAAAAACCjaQoAAAAAkNE0BQAAAADIdLa6gBEvpcbD48YVpzzw8RcXs1+86wvFbLvOCf2vK9ORyr3xnqq34fir7zy8OOeeh15QzGYdd0cx6125sphBK1Vz9yhmqzcYW8x6xzZe/xERG3xoYTG7cNbFxay0Jnf59snFOducfld5e48/UcygrY3pKEarXrVXMVu2TXnNjn/NI8XsgBn3FbMvbHpTw/HZfzqqOGfrt99azGCd6GMN7XBN45cAX918XnHOlavK55Mfv/tNxayntzzvLzeXzym7/lI+xk45ZEnD8bfOvLE453tnvrqYbfalq4oZNJIu3aKY/XrHi4rZrte8o5hN+smUhuNTf3R1/wsDGnpy92nF7Pa3fr2YNX5lFnHGzMvKc068tJ9V9W9fw7W/kjF9XFv52qOmlieePaRltA1XmgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAINPZ6gJGgmq/3YvZYx9b1XD8+r3PKc7pjiuK2Uuue08xe+apCcVs0gYri1kzjtrhmmJ24Y6/KGazTz2pmO3wz+VtMkqN6ShGHVMmF7MH3rtzMdvp1Xc3HH/Jhg8U5xw19RvFbOOO8rpr1sPdK4rZ1DHjGo7fesLXi3Neflt53U38+RP9LwwGoWP7bYrZPcdu2njODs8U51w159vFbMqY64rZZSvHFrPfPrVrMbv+iRcWs54ZNzQc7148sTgHWu3ub+5VzH61eXl9lczt6i1ml+/6kwFvLyIiyqfYQ+60Tat1tzPWCytev08xu2DWV4tZT9VVzG7e54fFbNVLuhuOH/++Q4tzrp63YzHb5vzGr1MjIsYteKyYdS9cVMxgpBr/rodbXQIjlCtNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ6Wx1Ae2iY/pGxezwMy8pZsdNXTjgfe38P+8vZtt96OoBb284XBIbFLOD7u8tZie87NJi9oeu8t9xtWpV/wqjLXW8aFYxW3zoxsVs2qsfKma/2/mnfeyx/H3WjN+vmF7MznpkbjG75s5ti9mGN4wrZpv9bkkx+8DFFzQcf9mElcU50A6W7TWjmK2esbrh+KTLyseawy78UFN1TD/vlmLW++yzxezBc8rHqPnbP9dwfNbZy8r7KiawbnzwgN8Ws6d6Gx9TjrznLcU5x295eTHbYMyKYtYRVTG7+KnditkHpl9RzJ6uUsPx7TonFOfstO/9xcxZKI08/PbG//dHRExOXUO+v67U+KX52Vv1cd7bV3ZEObpuVXldfumhQ4vZyp6xxeypz81sOL50+/KcLc5/sJh1L1xUzGCg3rnlNa0uISIirllVXg8nfu+kYjZl/0eL2R93//GgaqJvrjQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAECms9UFtIuHv7dJMTtu6iUD3t6e1x1ZzGZ99s/FrGfAe2ovu0xYWMwu6yz/HVerVg1HOQyhtPcuxeyYcy4oZq+c8HAxG5NSMbth1bj+FbaWHzwxt+H4jV/dozhn+mXl79vuRYuL2az4S7/ryt3/qf2L2csmrGw4fvnK8t/H5HuXFbPe/pcFgzL53KuL2axz110dzX7P7z5zUTH76bIXN97XLXc0uTcYGtV+uxezt2xwWjH7tyWHNBzvedlDxTnfjO37X9gQeNeeJxSz+988peH47e8qP+fb7ppZzGbFkv4XBs9jzk1HFLOJ396wmP1lp8Yvzccd+Hhxzr6bPljMPjaj/Br2JV0Ti9mPt/ldMetL93cbv5LtjI7inC8eP7uYXbrrpKbqYPTqPXDPYrZj15nrrI49rjq2mHXfP7mYbXvKVU3t74d3lI9v75xSfp1L/7jSFAAAAAAgo2kKAAAAAJDRNAUAAAAAyGiaAgAAAABkNE0BAAAAADKNP6JvPTVmYvlTAk/Y4U9NbfPB7mcbjm/5b+XP7+15/Imm9rUu9fXJczt0lj/V7ZQHDy5vc7lPJh3JHnpp40+qjYh446Typ8jveOn7itkWPx1bzCacf23/Cvs7jT99fmqUP9m7u8k9NWvGNavL4XGNh7/98MHFKb233jm4goD4/AvPL2aHnffhhuPb9fH/CqwLfz6qq5ht0lE+7/31VXs0HN+hjb6nq5vml8M379dw+MneFcUpm1wxql72MAReM/v/itmqqnz2mH4yvZiNv2BeMdv8gkJwanFK3FuO4sQXlT/B+4HXb1zMOp4rb/OZbXqK2cTNn2k4fu0+3y/OOXHarcXs0mi8zhnl5uxWjD519pnFbO+u8vduM36+fKNitu1Hny5m3ffd1tT+OnaeXcy2GHtHU9ukf1xpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACATGerC1iXlhyzRzE7buoVTW3zdTec0HB8i/nzm9peu1iy74RiNmXM+GL2fws2L2Y7xJJB1URrbfGtm4vZnuPeX8xmff2WYta7fPlgShqxHp478P96X73xbcXsx1Fed8BfPf32OcVsy87ritmsMx5rON4z6IpgcI7a/8qm5m133sohrmTopa6uYnbwoTc3HH+sJxXnTJ/3SDGzlmnklBnl14fzVk0qZtPOmjcc5QxYz+13F7Mt+8iG2rX3ll877tk1Ol8L0LeOHbYtZkedfUEx27tr3f1v/q+//Mditt19Vw/5/ha8aXoxe9mEZ4Z8fyVLz5pZzDaMReusjnXJlaYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMh0trqAdWnm2+8b8m1OOn/KkG+zHRx1zG+amjf7SyuKWW+zxdAWep99tpht8bmryvOGo5gRrmd81eoSYFR6+OU9xexrT+5YzHrve2A4yoGW6Vy6suF4Ox2zO7bYrJidvsXPGo8v3ak4p+fPQ/86gPXb9asmFrP3/O7dxWxWXDsc5bS9p98+p+H43PE3FOc865SYBu5594xi9sbJj67DSiIOuOnIhuPbffjqdVpHu9jo1qXFrJ3OIYaSK00BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAgo2kKAAAAAJDpbHUBQ25MRzF6QdczTW3y/OUbFrPpF93VcLynqT21j70mLChmj/Y8W8zS4keHoRrg7hWbtroEGBHS2HHF7JSDf1bMPvnLtxWz7brnDaomGC4/mv+SYnbJRrOL2dQljw1HOUPq7uM3G/CcL139ymI2K64fTDmMQh/+3AnFbNPl1TqsZGRYPTE1HB8TjcehZNacBcVszDBc93fH6tXFbMJ3Nhzy/TXj9veeXsxWV0P7dzLrt8eXs1tuGNJ9jQSuNAUAAAAAyGiaAgAAAABkNE0BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQKaz1QUMtY5pU4vZGTMvaWqbn/+vI4vZtCfmNbXNdtF70J4Nx/fuKj+v4xa8vpj1PP7EoGuC9V4a+JTffmNuMZseI/v/IRhKK/5hj2J2xOSri9kZf+wZhmpgeG33jpubmtcu3+0dG5bP27/11jOK2XWrqobjL/p/DxXndPe/LIiIiOnfcX61tjR2XDHb6703D3h7+3z/g8Vsa+e3o1Z1bFcx2/m4k4vZNvssbGp/9z2ycTHb9hfXNrXNZtz7xTnFbHV1QzHrjd4hreNFn1hSzEbjsdSVpgAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAgo2kKAAAAAJDRNAUAAAAAyHS2uoChVq1YWczes/CgYvbIig2K2cbn317MevpXVtta+pHlDccnp67inPkXzS5mW8ZVg64J1neff905A54z4zcPFrPuwRQD65kHD6+K2Wvuel0xm/DrG4tZeYvAYCw9bKdidvD4PxSz7X91YsPxWYuvG3RNQNmYbWYWs9O3OG/A29vsKmex/L3u+xYUs20+Xs6atW0sGvJtlnTssG0xO+V1/7vO6uhL96LFrS6hrbjSFAAAAAAgo2kKAAAAAJDRNAUAAAAAyGiaAgAAAABkNE0BAAAAADKapgAAAAAAmc5WFzDUep99tpg9fED56Y6ZXO4f9yxdNqia2tknZl844Dlb//DBYtY9mGJglOhIvcXs6AWHNBzveeSx4SoH1isXvvJrxewN//vBYrZt9+LhKAdGvTHjxxezz332W8Xsid4VxWz26Y3P96v+lwU04f53zBjwnLOe2ryYTZx3dzHrGfCeoP31Tp5QzN44+dE+Zg7t9Y4H3HRkMdsoyutyNHKlKQAAAABARtMUAAAAACCjaQoAAAAAkNE0BQAAAADIaJoCAAAAAGTKHye/Hqq6y5/t3rN02TqsZN3qPXDPYvbyCVcXknHDUwyMEtXcPYrZXl1XFLMvPj2t4fik1U8OtiRYbzx59H7FbGH3HcVs1umLiln5DAEYjKVv2qOYze26qpi9Z+E/FLPqpvmDKQnoQ8fG04vZh9/+swFv7xunvamYbbK0/H8ArI8Wv2JqMRvTxzWNY1NHMVtdlfd3x+rVDccnfGfD8iT+hitNAQAAAAAymqYAAAAAABlNUwAAAACAjKYpAAAAAEBG0xQAAAAAIKNpCgAAAACQ6Wx1AQy/e44t98YnpHENxz+0ZJ/inJ4ZG5Z3tnBRf8uC9doDr5pQzDbrKGfA85v0zoeK2S+f3LOYdT+wcDjKAfrw5VNO6yNNxeTKP+xSzLaJeYOoCOjL8jnbFbNjpvxuwNvb/KLFxax7wFuD9rfo4/sXswtPPLWY9UZXMVtdlffXG73F7OgvfrDh+Ca/uKq8Qf6GK00BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAgo2kKAAAAAJDpbHUBDI2OadOK2XdfetaAt3fpOfsUsxkTVhQzXXiombrn460uAUa01NVVzL64/XnF7C0Xn1zMZsW1g6oJaGzZO+cUsznjby5ml60onzlu/6V7illPv6oCmvHgG3ubmvf+h/ZvON7z0JLBlANtqWPGJsXsk+/6UTHbvLN8ftusRd2ritmUB7qHfH+jjR4XAAAAAEBG0xQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAyna0ugKGx8N07FbODx/9+wNs7/J/+VMxu+p+Zxax7wHuC0WdMpFaXAG1vzAaTi9nEVD7aTFzk1AbWtVM/861itrrqKWbv++5JxWzLx64aVE1AWedW5ddzvznkq33MnFBMLrlndsPxbVbd0t+yYMRYcPz2xez1ky5ah5VEnHTPEcVs/AXXrsNK1k+uNAUAAAAAyGiaAgAAAABkNE0BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQKaz1QUwNFbt/cyQbu+X/31gMdvs4WuGdF8w2vRGVcye/OOmDccnxX3DVQ60pcdfO6uYzRo7vphtde7DxaxnUBXB6PbkMfsVs/26bihmV64cW8y2/OxVg6oJaM7iw2cWs+06JxSzp3pXFrNtvtw7qJpgJJm6/yPFbMwwXJv4hSdeVMw6jy6/tuwe8kpGH1eaAgAAAABkNE0BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAg09nqAhgaH939t0O6vZk/f6iYdff2DOm+YKQaM2lSMTt6m6uL2Q+e2qKYvfDLNzYc7+1/WTBipK6uYrbribcVs0PveEMx67zn/sGUBBSc8u/fLWZjIhWz/zz26D7m3TSomoDmTH7NkqbmHXZreT1Pu7Z83IYRa85uDYcv3+37xSm9w/DK7TvXH1jMZi26fsj3x1+50hQAAAAAIKNpCgAAAACQ0TQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAAJnOVhdA/3XM3r6YHTjxyj5mTigmB932lobjkxY80N+yYNR69J27FbPjp15ezHY8933FbPuVVw+qJhhJ0uxtitkZM88pZvt+qryGpseDg6oJRrN7vjynmB004bpidsrjuxezMX+8aVA1Ae3jyfkbF7Np8ed1WAmsG3cfP67VJdBirjQFAAAAAMhomgIAAAAAZDRNAQAAAAAymqYAAAAAABlNUwAAAACATGerC6D/Fh6+STHbrnNCU9vs/Pr0xkHvfU1tD9Y3C/5jv2J267Ff62Nm+WdS45b5eRVERNz9kfKx66TFc4vZ9O/MG45yYNTo3HRGw/Gfv/Er5TlR/gThs2+eU8x2iBv7XRcwdMaMH1/MXjrjnmL2o6fLrzl3OGNJMevpX1kAI4pX7gAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAgo2kKAAAAAJDRNAUAAAAAyHS2ugD6b6M7uovZg93PFrNPLH5tMZv4p7sajvf0vyxYr22woJyN6ePnTrvPO7qYbX3qzcWstx81wUjTseHUhuM/mHtmcc6x57yvmG0d8wZdE4xm0362quH4zmPHNbW9WV9pvL2IiKqpLQKD1btyZTG7/JHti9lPr5tbzLa+x/GX0WXWsdc3HH9tvHjd1hGN62D4udIUAAAAACCjaQoAAAAAkNE0BQAAAADIaJoCAAAAAGQ0TQEAAAAAMpqmAAAAAACZzlYXQP+Nv/DaYnbihQf0MXPpkNcCo8X0M+cVs9ee+eJiNjP+r5j1DqoiGHl6li5rOP6Zbfcqztk6ymsPGJzH9l/acPzVUV6TfZvfdC3AujfpH+4rZ1HOAEYbV5oCAAAAAGQ0TQEAAAAAMpqmAAAAAAAZTVMAAAAAgIymKQAAAABARtMUAAAAACCTqqrq/xen9FhEPDB85UDb2qqqqhe0uoi1WZOMctYltBdrEtqPdQntpS3XZIR1yahWXJcDapoCAAAAAKzv3J4PAAAAAJDRNAUAAAAAyGiaAgAAAABkNE0BAAAAADKapgAAAAAAGU1TAAAAAICMpikAAAAAQEbTFAAAAAAgo2kKAAAAAJD5/8CBcUwqKIFdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1728x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the query example and its top 5 neighbors\n",
    "viz_neigbors_imgs(qx[0], qy[0], nns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af823514-33a8-4a69-9717-1ed0d636a80d",
   "metadata": {},
   "source": [
    "## Xtra\n",
    "### - MNIST and looking at an image\n",
    "Refer to https://github.com/tensorflow/similarity/blob/master/examples/supervised_hello_world.ipynb\n",
    "\n",
    "`Convert a NumPy array to an image`  \n",
    "Refer to https://www.geeksforgeeks.org/convert-a-numpy-array-to-an-image/  \n",
    "Since images are just an array of pixels carrying various color codes. NumPy can be used to convert an array into image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ee94af73-c8ff-4227-b361-6687331e9c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.9.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "\n",
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "703efa9c-a9c3-436d-97f5-0e2cba19dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "print(y_train[0])\n",
    "\n",
    "#view an image example\n",
    "from PIL import Image as im\n",
    "# creating image object of above array\n",
    "data = im.fromarray(x_train[0]) #class 'PIL.Image.Image'\n",
    "data\n",
    "\n",
    "# saving the final output as a PNG file\n",
    "#data.save('image.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
